{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Sentinel-2 Farm Monitoring\n",
    "# The process  generate and save only PNG figures for the maps and figures, and print the numerical median/maximum values directly to the console.\n",
    "\n",
    "# **Prerequisites:**\n",
    "# 1.  An active Sentinel Hub account.\n",
    "# 2.  `eolearn` (including `eolearn-core`, `eolearn-features`), `sentinelhub`, `numpy`, `geojson`, `tqdm`, `matplotlib`, `rasterio`, `shapely` libraries installed.\n",
    "# 3.  Your Sentinel Hub `SH_CLIENT_ID` and `SH_CLIENT_SECRET` configured (e.g., in `config.py` or environment variables).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import geojson\n",
    "from tqdm.notebook import tqdm\n",
    "# Sentinel Hub and eo-learn imports\n",
    "from sentinelhub import SHConfig, SentinelHubRequest, DataCollection, MimeType, BBox, CRS\n",
    "from eolearn.core import EOTask, EOPatch, FeatureType\n",
    "from eolearn.io import SentinelHubInputTask # Using SentinelHubInputTask for idiomatic data fetching\n",
    "from eolearn.features.ndi import NormalizedDifferenceIndexTask # Used for NDVI and NDMI\n",
    "# For plotting maps with polygons\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio # Still needed for transform calculation in plot_map_with_polygon\n",
    "from shapely.geometry import shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output directory\n",
    "output_dir = 'farm_analysis_results_eolearn_best_practice'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Results will be saved in: {os.path.abspath(output_dir)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 2. Core Functions\n",
    "\n",
    "# %%\n",
    "def authorize_sentinelhub():\n",
    "    \"\"\"\n",
    "    Sets up and verifies Sentinel Hub configuration.\n",
    "    \"\"\"\n",
    "    config = SHConfig()\n",
    "    if not config.sh_client_id or not config.sh_client_secret:\n",
    "        print(\"Sentinel Hub credentials not found in config or environment variables.\")\n",
    "        print(\"Please ensure SH_CLIENT_ID and SH_CLIENT_SECRET are set.\")\n",
    "        raise SystemExit(\"Exiting: Sentinel Hub credentials are required.\")\n",
    "    print(\"Sentinel Hub configuration loaded successfully.\")\n",
    "    return config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_farm_polygon(polygon_path='farm_polygon.geojson'):\n",
    "    \"\"\"\n",
    "    Retrieves a farm polygon from a GeoJSON file or creates a sample one if it doesn't exist.\n",
    "    Uses the provided 'Test_area_Gedaref' GeoJSON as the sample.\n",
    "    Returns the GeoJSON geometry object and a Sentinel Hub BBox object.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(polygon_path):\n",
    "        sample_farm_geojson = {\n",
    "            \"type\": \"FeatureCollection\",\n",
    "            \"name\": \"Test_area_Gedaref\",\n",
    "            \"crs\": { \"type\": \"name\", \"properties\": { \"name\": \"urn:ogc:def:crs:OGC:1.3:CRS84\" } },\n",
    "            \"features\": [\n",
    "                {\n",
    "                    \"type\": \"Feature\",\n",
    "                    \"properties\": { \"id\": 1 },\n",
    "                    \"geometry\": {\n",
    "                        \"type\": \"MultiPolygon\",\n",
    "                        \"coordinates\": [ [ [ [ 35.059705226904711, 12.986947971349911 ], [ 35.118561634226467, 13.039248827197715 ], [ 35.194094730861465, 12.98417757904055 ], [ 35.132480092482808, 12.927274341651565 ], [ 35.059705226904711, 12.986947971349911 ] ] ] ]\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        with open(polygon_path, 'w') as f:\n",
    "            geojson.dump(sample_farm_geojson, f)\n",
    "        print(f\"Created a sample farm polygon GeoJSON at: {polygon_path}\")\n",
    "        print(\"NOTE: This uses the 'Test_area_Gedaref' polygon as the default. Modify 'farm_polygon.geojson' for your specific farm.\")\n",
    "\n",
    "    with open(polygon_path, 'r') as f:\n",
    "        farm_geojson = geojson.load(f)\n",
    "\n",
    "    farm_geometry = farm_geojson['features'][0]['geometry']\n",
    "    shapely_polygon = shape(farm_geometry)\n",
    "    minx, miny, maxx, maxy = shapely_polygon.bounds\n",
    "    bbox_sh = BBox(bbox=(minx, miny, maxx, maxy), crs=CRS.WGS84)\n",
    "\n",
    "    print(f\"Farm polygon loaded/created. Bounding Box: {bbox_sh}\")\n",
    "    return farm_geometry, bbox_sh\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalculateAllIndices(EOTask):\n",
    "    \"\"\"\n",
    "    EO-Learn Task to calculate NDVI, EVI, MSAVI, and NDMI.\n",
    "    EVI and MSAVI are calculated manually as their dedicated EOTasks are missing.\n",
    "    \"\"\"\n",
    "    def execute(self, eopatch):\n",
    "        if FeatureType.DATA not in eopatch or 'BANDS' not in eopatch[FeatureType.DATA]:\n",
    "            raise ValueError(\"BANDS feature not found in EOPatch. Cannot calculate indices.\")\n",
    "\n",
    "        # Sentinel-2 L2A band indices based on the order requested from SentinelHubInputTask (B2, B3, B4, B8, B11)\n",
    "        # Note: BANDS data is already scaled to reflectance [0-1] by SentinelHubInputTask\n",
    "        bands = eopatch.data['BANDS'] # Shape: (time, height, width, bands_count)\n",
    "        \n",
    "        # Extract bands for calculations\n",
    "        # B2: Blue (idx 0), B3: Green (idx 1), B4: Red (idx 2), B8: NIR (idx 3), B11: SWIR1 (idx 4)\n",
    "        B2 = bands[..., 0] # Blue\n",
    "        B3 = bands[..., 1] # Green\n",
    "        B4 = bands[..., 2] # Red\n",
    "        B8 = bands[..., 3] # NIR\n",
    "        B11 = bands[..., 4] # SWIR1\n",
    "\n",
    "        # NDVI: (B8 - B4) / (B8 + B4)\n",
    "        # Using NormalizedDifferenceIndexTask as it was confirmed to be available.\n",
    "        ndvi = NormalizedDifferenceIndexTask((FeatureType.DATA, 'BANDS', (3, 2))).execute(eopatch).data['NDVI']\n",
    "        eopatch.add_feature(FeatureType.DATA, 'NDVI', ndvi)\n",
    "\n",
    "        # MSAVI: (2 * NIR + 1 - sqrt((2 * NIR + 1)^2 - 8 * (NIR - Red))) / 2\n",
    "        # Insight: Manually calculating MSAVI because the EOTask for it is missing.\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            term_under_sqrt = (2 * B8 + 1)**2 - 8 * (B8 - B4)\n",
    "            msavi = np.where(term_under_sqrt >= 0, (2 * B8 + 1 - np.sqrt(term_under_sqrt)) / 2, np.nan)\n",
    "        eopatch.add_feature(FeatureType.DATA, 'MSAVI', msavi[..., np.newaxis]) # Add newaxis to maintain (h,w,1) or (t,h,w,1) shape\n",
    "\n",
    "        # EVI: 2.5 * ((B8 - B4) / (B8 + 6 * B4 - 7.5 * B2 + 1))\n",
    "        # Insight: Manually calculating EVI because the EOTask for it is missing.\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            numerator_evi = B8 - B4\n",
    "            denominator_evi = B8 + 6 * B4 - 7.5 * B2 + 1\n",
    "            evi = 2.5 * np.where(denominator_evi != 0, numerator_evi / denominator_evi, np.nan)\n",
    "        eopatch.add_feature(FeatureType.DATA, 'EVI', evi[..., np.newaxis]) # Add newaxis to maintain (h,w,1) or (t,h,w,1) shape\n",
    "\n",
    "        # NDMI (Normalized Difference Moisture Index) / NDWI (Gao's version)\n",
    "        # Formula: (NIR - SWIR1) / (NIR + SWIR1)\n",
    "        # Using NormalizedDifferenceIndexTask as it was confirmed to be available.\n",
    "        ndmi = NormalizedDifferenceIndexTask((FeatureType.DATA, 'BANDS', (3, 4))).execute(eopatch).data['NDMI']\n",
    "        eopatch.add_feature(FeatureType.DATA, 'NDMI', ndmi)\n",
    "\n",
    "        print(\"  All specified indices calculated within EOPatch.\")\n",
    "        return eopatch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_full_eolearn_processing(bbox, time_interval_str, config, size=(100, 100)):\n",
    "    \"\"\"\n",
    "    Runs a full EO-Learn processing pipeline for a given time interval and bounding box.\n",
    "    Uses SentinelHubInputTask to fetch data, calculates indices, applies cloud masking,\n",
    "    and computes median/max values.\n",
    "    Returns the processed EOPatch.\n",
    "    \"\"\"\n",
    "    start_date, end_date = time_interval_str\n",
    "    print(f\"  Processing EOPatch for interval: {start_date} to {end_date}...\")\n",
    "\n",
    "    input_task = SentinelHubInputTask(\n",
    "        data_collection=DataCollection.SENTINEL2_L2A,\n",
    "        bands=['B02', 'B03', 'B04', 'B08', 'B11', 'SCL'], # Removed B5 (Red Edge 1)\n",
    "        bands_feature=(FeatureType.DATA, 'BANDS'), \n",
    "        mosaicking_order='leastRecent',\n",
    "        resolution=10, \n",
    "        time_difference=datetime.timedelta(minutes=60),\n",
    "        config=config\n",
    "    )\n",
    "\n",
    "    calculate_indices_task = CalculateAllIndices()\n",
    "\n",
    "    # Insight: Reverted to direct task chaining, as LinearWorkflow caused ModuleNotFoundError.\n",
    "    # This is a robust alternative for sequential operations.\n",
    "    try:\n",
    "        # Step 1: Execute input_task to get the EOPatch with raw bands\n",
    "        eopatch = input_task.execute(bbox=bbox, time_interval=time_interval_str)\n",
    "\n",
    "        if not eopatch.timestamps:\n",
    "            print(f\"  No valid timestamps/scenes found for this interval. Returning None.\")\n",
    "            return None\n",
    "\n",
    "        print(f\"  Retrieved {len(eopatch.timestamps)} images in EOPatch.\")\n",
    "\n",
    "        # Step 2: Execute calculate_indices_task on the obtained EOPatch\n",
    "        eopatch = calculate_indices_task.execute(eopatch)\n",
    "\n",
    "        # Compute Median and Maximum Values per Index (over time axis) with cloud masking\n",
    "        print(\"  Calculating median and maximum values with cloud masking...\")\n",
    "        \n",
    "        # SCL (Scene Classification Layer) is extracted from the 'BANDS' feature (index 5)\n",
    "        # and used for robust cloud/shadow masking.\n",
    "        scl_mask = eopatch.data['BANDS'][:, :, :, 5].astype(np.uint8) # SCL is at index 5 in the BANDS list\n",
    "        \n",
    "        # SCL values to mask: 0-No data, 3-Cloud shadows, 8-Cloud medium probability, 9-Cloud high probability, 10-Thin cirrus\n",
    "        valid_pixel_mask = ~((scl_mask == 0) | (scl_mask == 3) | (scl_mask == 8) | (scl_mask == 9) | (scl_mask == 10))\n",
    "        valid_pixel_mask = valid_pixel_mask[:, :, :, np.newaxis]\n",
    "\n",
    "        indices_to_analyze = ['NDVI', 'MSAVI', 'EVI', 'NDMI'] # Insight: List of indices to analyze\n",
    "\n",
    "        for index_name in indices_to_analyze:\n",
    "            index_data = eopatch.data[index_name]\n",
    "            masked_index_data = np.where(valid_pixel_mask, index_data, np.nan)\n",
    "            median_value = np.nanmedian(masked_index_data, axis=0)\n",
    "            max_value = np.nanmax(masked_index_data, axis=0)\n",
    "            eopatch.add_feature(FeatureType.DATA, f'{index_name}_MEDIAN', median_value.astype(np.float32))\n",
    "            eopatch.add_feature(FeatureType.DATA, f'{index_name}_MAX', max_value.astype(np.float32))\n",
    "            \n",
    "            # Insight: Print numerical median and max values to console as requested.\n",
    "            # Using np.nanmedian for a summary of the whole map's median/max values.\n",
    "            overall_median = np.nanmedian(median_value)\n",
    "            overall_max = np.nanmax(max_value)\n",
    "            print(f\"    {index_name} ({time_interval_str[0]} to {time_interval_str[1]}): Overall Median={overall_median:.4f}, Overall Max={overall_max:.4f}\")\n",
    "\n",
    "\n",
    "        print(\"  Median and maximum values calculated for all indices and added to EOPatch.\")\n",
    "        return eopatch\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  An error occurred during EO-Learn workflow execution for {time_interval_str}: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_time_periods():\n",
    "    \"\"\"\n",
    "    Defines and returns time intervals for analysis.\n",
    "    \"\"\"\n",
    "    today = datetime.date.today()\n",
    "    last_5_days_start = today - datetime.timedelta(days=5)\n",
    "    last_10_days_start = today - datetime.timedelta(days=10)\n",
    "    past_3_months_start = today - datetime.timedelta(days=90)\n",
    "\n",
    "    time_intervals_for_maps = {\n",
    "        \"last_5_days\": (last_5_days_start, today),\n",
    "        \"last_10_days\": (last_10_days_start, today),\n",
    "        \"past_3_months\": (past_3_months_start, today)\n",
    "    }\n",
    "\n",
    "    time_intervals_str_for_maps = {\n",
    "        name: (start.strftime(\"%Y-%m-%d\"), end.strftime(\"%Y-%m-%d\"))\n",
    "        for name, (start, end) in time_intervals_for_maps.items()\n",
    "    }\n",
    "    \n",
    "    past_3_months_interval_str = (past_3_months_start.strftime(\"%Y-%m-%d\"), today.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    return time_intervals_str_for_maps, past_3_months_interval_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map_with_polygon(eopatch, feature_name, farm_geometry, title=\"\", cmap='viridis', vmin=None, vmax=None):\n",
    "    \"\"\"\n",
    "    Plots a specific feature map directly from an EOPatch, with the farm polygon overlay, saving as PNG.\n",
    "    Insight: Modified to plot directly from EOPatch data (in-memory), no GeoTIFF export/load needed.\n",
    "    \"\"\"\n",
    "    if FeatureType.DATA not in eopatch or feature_name not in eopatch[FeatureType.DATA]:\n",
    "        print(f\"  Feature '{feature_name}' not found in EOPatch. Cannot plot map.\")\n",
    "        return\n",
    "\n",
    "    data_to_plot = eopatch.data[feature_name]\n",
    "    \n",
    "    # Ensure data is 2D (height, width) for plotting, remove singleton last dim if present\n",
    "    if data_to_plot.ndim == 3 and data_to_plot.shape[-1] == 1:\n",
    "        data_to_plot = data_to_plot[:, :, 0]\n",
    "    elif data_to_plot.ndim != 2:\n",
    "        print(f\"  Error: Data for feature '{feature_name}' has unexpected shape {data_to_plot.shape}. Expected 2D or 3D with last dim 1.\")\n",
    "        return\n",
    "\n",
    "    # Derive extent from EOPatch bbox\n",
    "    bbox = eopatch.bbox\n",
    "    extent = [bbox.min_x, bbox.max_x, bbox.min_y, bbox.max_y]\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    im = plt.imshow(data_to_plot, cmap=cmap, vmin=vmin, vmax=vmax, extent=extent, origin='upper')\n",
    "\n",
    "    from matplotlib.patches import Polygon as MplPolygon\n",
    "\n",
    "    # Robustly handle both Polygon and MultiPolygon geometry types for plotting.\n",
    "    if farm_geometry['type'] == 'MultiPolygon':\n",
    "        for poly_coords_list in farm_geometry['coordinates']:\n",
    "            outer_ring_coords = poly_coords_list[0]\n",
    "            poly_patch = MplPolygon(outer_ring_coords, closed=True, edgecolor='red', facecolor='none', linewidth=2, alpha=0.7)\n",
    "            plt.gca().add_patch(poly_patch)\n",
    "    else: # Assume Polygon\n",
    "        polygon_coords = farm_geometry['coordinates'][0]\n",
    "        poly_patch = MplPolygon(polygon_coords, closed=True, edgecolor='red', facecolor='none', linewidth=2, alpha=0.7)\n",
    "        plt.gca().add_patch(poly_patch)\n",
    "\n",
    "\n",
    "    plt.colorbar(im, label=\"Index Value\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Longitude\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    output_fig = os.path.join(output_dir, f'{title.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")}.png')\n",
    "    \n",
    "    # Using current date and time in filename to avoid overwriting previous runs\n",
    "    timestamp_str = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_fig_dated = output_fig.replace('.png', f'_{timestamp_str}.png')\n",
    "    \n",
    "    plt.savefig(output_fig_dated, dpi=300)\n",
    "    print(f\"  Saved figure to: {output_fig_dated}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series(eopatch_for_ts, output_dir, index_name='NDVI'):\n",
    "    \"\"\"\n",
    "    Generates a time series plot of median values for a specified index\n",
    "    from an already processed EOPatch (for the entire period).\n",
    "    Applies cloud masking to each time slice before computing median.\n",
    "    Insight: This function efficiently extracts time series data from an existing EOPatch,\n",
    "    avoiding redundant Sentinel Hub requests for each time chunk.\n",
    "    \"\"\"\n",
    "    if not eopatch_for_ts or FeatureType.DATA not in eopatch_for_ts or index_name not in eopatch_for_ts.data:\n",
    "        print(f\"  EOPatch or '{index_name}' data not available for time series plotting.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n--- Generating {index_name} Time Series Plot from EOPatch ---\")\n",
    "    \n",
    "    time_series_values = []\n",
    "    date_labels = []\n",
    "\n",
    "    index_data_all_times = eopatch_for_ts.data[index_name] # Shape: (time, height, width, 1)\n",
    "    # SCL is last band in 'BANDS' feature as retrieved by SentinelHubInputTask\n",
    "    scl_data_all_times = eopatch_for_ts.data['BANDS'][:, :, :, 5].astype(np.uint8) # SCL is at index 5 in the BANDS list\n",
    "\n",
    "    for i, timestamp in enumerate(eopatch_for_ts.timestamps):\n",
    "        current_index_map = index_data_all_times[i, :, :, 0] # Remove last dimension if present\n",
    "        current_scl_map = scl_data_all_times[i, :, :]\n",
    "\n",
    "        # SCL values to mask: 0-No data, 3-Cloud shadows, 8-Cloud medium probability, 9-Cloud high probability, 10-Thin cirrus\n",
    "        valid_mask = ~((current_scl_map == 0) | (current_scl_map == 3) | (current_scl_map == 8) | (current_scl_map == 9) | (current_scl_map == 10))\n",
    "\n",
    "        masked_index_data = np.where(valid_mask, current_index_map, np.nan)\n",
    "        \n",
    "        if not np.all(np.isnan(masked_index_data)):\n",
    "            median_val = np.nanmedian(masked_index_data)\n",
    "            time_series_values.append(median_val)\n",
    "        else:\n",
    "            time_series_values.append(np.nan) # Append NaN if entire image is masked\n",
    "\n",
    "        date_labels.append(timestamp.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    if time_series_values:\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        # Use different colors for different indices in time series\n",
    "        if index_name == 'NDVI':\n",
    "            color = 'green'\n",
    "        elif index_name == 'MSAVI':\n",
    "            color = 'purple'\n",
    "        elif index_name == 'EVI':\n",
    "            color = 'blue'\n",
    "        elif index_name == 'NDMI':\n",
    "            color = 'cyan'\n",
    "        else:\n",
    "            color = 'gray' # Fallback for any other index\n",
    "\n",
    "        plt.plot(date_labels, time_series_values, marker='o', linestyle='-', color=color) \n",
    "        plt.title(f\"{index_name} Time Series (Median per Scene - Full Period)\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(f\"Median {index_name}\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        output_fig_path = os.path.join(output_dir, f\"{index_name}_time_series_full_period.png\")\n",
    "        \n",
    "        # Using current date and time in filename to avoid overwriting previous runs\n",
    "        timestamp_str = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_fig_dated = output_fig_path.replace('.png', f'_{timestamp_str}.png')\n",
    "\n",
    "        plt.savefig(output_fig_dated, dpi=300)\n",
    "        print(f\"Saved {index_name} time series plot to: {output_fig_dated}\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        print(f\"No valid data points collected for {index_name} time series plot.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ## 3. Main Execution Workflow\n",
    "\n",
    "# %%\n",
    "# 1. Authorize Sentinel Hub\n",
    "sh_config = authorize_sentinelhub()\n",
    "\n",
    "# 2. Get or Create Farm Polygon\n",
    "farm_geometry, farm_bbox = get_or_create_farm_polygon()\n",
    "\n",
    "# 3. Define Time Periods\n",
    "time_intervals_str_for_maps, past_3_months_interval_str = define_time_periods()\n",
    "\n",
    "# Insight: List of indices to analyze (NDVI, MSAVI, EVI, NDMI) based on conditional\n",
    "indices_to_analyze = ['NDVI', 'MSAVI', 'EVI', 'NDMI']\n",
    "\n",
    "# Store EOPatches for potential later use\n",
    "processed_eopatches = {}\n",
    "\n",
    "# 4. Process Indices and Generate Maps for Each Timeframe\n",
    "print(\"\\n--- Starting Main Index Processing and Map Generation ---\")\n",
    "for timeframe_name, interval_str in tqdm(time_intervals_str_for_maps.items(), desc=\"Overall Processing\"):\n",
    "    print(f\"\\nProcessing data for {timeframe_name}...\")\n",
    "    # Call the main EO-Learn processing function which fetches data and calculates all\n",
    "    # indices efficiently into a single EOPatch for the entire interval.\n",
    "    eopatch_result = run_full_eolearn_processing(farm_bbox, interval_str, sh_config)\n",
    "\n",
    "    if eopatch_result:\n",
    "        processed_eopatches[timeframe_name] = eopatch_result\n",
    "        # Generate maps (PNG figures) for each index\n",
    "        for index_name in indices_to_analyze:\n",
    "            median_feature_name = f'{index_name}_MEDIAN'\n",
    "            max_feature_name = f'{index_name}_MAX'\n",
    "\n",
    "            # Plot Median Map (PNG)\n",
    "            plot_map_with_polygon(\n",
    "                eopatch_result, # Pass EOPatch directly\n",
    "                median_feature_name, # Pass feature name\n",
    "                farm_geometry,\n",
    "                title=f\"{index_name} Median ({timeframe_name}) with Farm Polygon\",\n",
    "                # Adjust vmin/vmax for specific indices if needed\n",
    "                vmin=0.0 if index_name in ['NDVI', 'EVI', 'MSAVI'] else -1.0,\n",
    "                vmax=1.0\n",
    "            )\n",
    "\n",
    "            # Plot Max Map (PNG)\n",
    "            plot_map_with_polygon(\n",
    "                eopatch_result, # Pass EOPatch directly\n",
    "                max_feature_name, # Pass feature name\n",
    "                farm_geometry,\n",
    "                title=f\"{index_name} Max ({timeframe_name}) with Farm Polygon\",\n",
    "                vmin=0.0 if index_name in ['NDVI', 'EVI', 'MSAVI'] else -1.0,\n",
    "                vmax=1.0\n",
    "            )\n",
    "    else:\n",
    "        print(f\"Skipping map generation for {timeframe_name} due to processing issues.\")\n",
    "\n",
    "# 5. Generate Time Series Plot (for NDVI over past 3 months as requested)\n",
    "print(\"\\n--- Starting Time Series Plot Generation ---\")\n",
    "# The time series plot directly uses the already processed EOPatch\n",
    "# for the 'past_3_months' period, avoiding redundant Sentinel Hub calls.\n",
    "# You can change 'NDVI' to 'MSAVI', 'EVI', or 'NDMI' to plot their time series.\n",
    "if \"past_3_months\" in processed_eopatches and processed_eopatches[\"past_3_months\"] is not None:\n",
    "    plot_time_series(processed_eopatches[\"past_3_months\"], output_dir, index_name='NDVI')\n",
    "    # Optional: Plot other indices time series as well, for example:\n",
    "    # plot_time_series(processed_eopatches[\"past_3_months\"], output_dir, index_name='MSAVI')\n",
    "    # plot_time_series(processed_eopatches[\"past_3_months\"], output_dir, index_name='EVI')\n",
    "    # plot_time_series(processed_eopatches[\"past_3_months\"], output_dir, index_name='NDMI')\n",
    "else:\n",
    "    print(\"Cannot generate time series plot: No valid EOPatch available for 'past_3_months'.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- All processing complete! Check the 'farm_analysis_results_eolearn_best_practice' directory. ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
